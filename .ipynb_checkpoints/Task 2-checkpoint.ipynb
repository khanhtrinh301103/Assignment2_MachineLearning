{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28472acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import concurrent.futures\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e54c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def is_image_file(filename):\n",
    "    \"\"\"Check if a file is an image based on its extension.\"\"\"\n",
    "    valid_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".gif\"]\n",
    "    return any(filename.lower().endswith(ext) for ext in valid_extensions)\n",
    "\n",
    "def extract_features(img_path, model):\n",
    "    \"\"\"Extract features from an image using the EfficientNetB0 model.\"\"\"\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(preprocessed_img)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / np.linalg.norm(flattened_features)\n",
    "    return normalized_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4a5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Processing\n",
    "def process_image(img_path, model):\n",
    "    return img_path, extract_features(img_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213ee3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction from Dataset\n",
    "def extract_features_from_dataset(directory, model, cache_path='features_cache_task2.pkl'):\n",
    "    \"\"\"Extract features from all images in the dataset.\"\"\"\n",
    "    if os.path.exists(cache_path):\n",
    "        with open(cache_path, 'rb') as f:\n",
    "            image_paths, features_list = pickle.load(f)\n",
    "    else:\n",
    "        image_paths = []\n",
    "        features_list = []\n",
    "        img_paths = []\n",
    "        for subdir, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if is_image_file(file):\n",
    "                    img_paths.append(os.path.join(subdir, file))\n",
    "\n",
    "        print(f\"Total images found: {len(img_paths)}\")\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            results = list(executor.map(lambda p: process_image(p, model), img_paths))\n",
    "        \n",
    "        print(f\"Features extracted for {len(results)} images\")\n",
    "        \n",
    "        for img_path, features in results:\n",
    "            image_paths.append(img_path)\n",
    "            features_list.append(features)\n",
    "\n",
    "        with open(cache_path, 'wb') as f:\n",
    "            pickle.dump((image_paths, features_list), f)\n",
    "    \n",
    "    print(f\"Total images processed: {len(image_paths)}\")\n",
    "    return image_paths, features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2797a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Recommendation\n",
    "def recommend_similar_images(features, all_features, all_paths, n=10):\n",
    "    \"\"\"Recommend n similar images based on feature similarity.\"\"\"\n",
    "    neighbors = NearestNeighbors(n_neighbors=n, metric='euclidean')\n",
    "    all_features = np.array(all_features)\n",
    "    neighbors.fit(all_features)\n",
    "    features = np.array(features).reshape(1, -1)\n",
    "    distances, indices = neighbors.kneighbors(features)\n",
    "    recommended_images = [all_paths[idx] for idx in indices.flatten()]\n",
    "    similarity_scores = distances.flatten()\n",
    "    print(f\"Top {n} similar images found with similarity scores: {similarity_scores}\")\n",
    "    return recommended_images, similarity_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3aebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Functions\n",
    "def display_images(image_paths):\n",
    "    \"\"\"Display images in a grid.\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = mpimg.imread(img_path)\n",
    "        plt.subplot(2, 5, i + 1)  # Adjust the grid size depending on how many images you want to show\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(os.path.basename(img_path))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New function to recommend similar images for an input image\n",
    "def recommend_similar_images_for_input_image(input_image_path, model, all_features, all_paths, n=10):\n",
    "    \"\"\"Recommend n similar images for an input image based on feature similarity.\"\"\"\n",
    "    input_image_features = extract_features(input_image_path, model)\n",
    "    recommended_images, similarity_scores = recommend_similar_images(input_image_features, all_features, all_paths, n)\n",
    "    print(f\"Similar images for {input_image_path}:\")\n",
    "    display_images(recommended_images)\n",
    "    return recommended_images, similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab661022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution Block\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the model\n",
    "    model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    # Dataset direction:\n",
    "    directory = 'train'  # Replace with your dataset path\n",
    "    image_paths, features_list = extract_features_from_dataset(directory, model)\n",
    "    \n",
    "    # Input image path for finding similar images\n",
    "    input_image_path = 'industry_bed.jpg'\n",
    "\n",
    "    # Select a feature for a specific image (for example, the first image in the dataset)\n",
    "    test_image_path = image_paths[0]\n",
    "    test_image_features = features_list[0]\n",
    "\n",
    "    # Recommend similar images\n",
    "    recommended_images, similarity_scores = recommend_similar_images(test_image_features, features_list, image_paths)\n",
    "\n",
    "    # Display recommended images\n",
    "    display_images(recommended_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e353c935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
