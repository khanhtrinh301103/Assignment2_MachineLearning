{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf38949",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'tensorflow.keras.preprocessing' (C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\_tf_keras\\keras\\preprocessing\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Input\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image, ImageDataGenerator\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Step 1: Define a Custom CNN Model Architecture\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'tensorflow.keras.preprocessing' (C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\_tf_keras\\keras\\preprocessing\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.preprocessing import image, ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Step 1: Define a Custom CNN Model Architecture\n",
    "def build_custom_model(input_shape=(224, 224, 3)):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))  # Reduce dimension for feature extraction\n",
    "    return model\n",
    "\n",
    "model = build_custom_model()\n",
    "model.summary()\n",
    "\n",
    "# Step 2: Prepare the Data\n",
    "data_dir = 'test'\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "def split_dataset_into_test_and_train_sets(all_data_dir=data_dir, train_test_ratio=0.8):\n",
    "    if not os.path.exists('train'):\n",
    "        os.makedirs('train')\n",
    "    if not os.path.exists('test'):\n",
    "        os.makedirs('test')\n",
    "\n",
    "    for type_dir in os.listdir(all_data_dir):\n",
    "        type_path = os.path.join(all_data_dir, type_dir)\n",
    "        if os.path.isdir(type_path):\n",
    "            for style_dir in os.listdir(type_path):\n",
    "                style_path = os.path.join(type_path, style_dir)\n",
    "                if os.path.isdir(style_path):\n",
    "                    train_style_dir = os.path.join('train', type_dir, style_dir)\n",
    "                    test_style_dir = os.path.join('test', type_dir, style_dir)\n",
    "                    os.makedirs(train_style_dir, exist_ok=True)\n",
    "                    os.makedirs(test_style_dir, exist_ok=True)\n",
    "\n",
    "                    file_list = glob.glob(os.path.join(style_path, '*.jpg'))\n",
    "                    random_set = np.random.permutation(file_list)\n",
    "                    train_list = random_set[:int(len(random_set) * train_test_ratio)]\n",
    "                    test_list = random_set[int(len(random_set) * train_test_ratio):]\n",
    "\n",
    "                    for file_path in train_list:\n",
    "                        if os.path.abspath(file_path) != os.path.abspath(os.path.join(train_style_dir, os.path.basename(file_path))):\n",
    "                            shutil.copy(file_path, train_style_dir)\n",
    "                    for file_path in test_list:\n",
    "                        if os.path.abspath(file_path) != os.path.abspath(os.path.join(test_style_dir, os.path.basename(file_path))):\n",
    "                            shutil.copy(file_path, test_style_dir)\n",
    "\n",
    "split_dataset_into_test_and_train_sets()\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25\n",
    ")\n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "valid_generator = train_data_gen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Step 3: Train the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.n // batch_size,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy - Furniture Dataset')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Extract Features Using the Trained Model\n",
    "def extract_features_custom(img_path, model, input_size=(224, 224)):\n",
    "    img = image.load_img(img_path, target_size=input_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    features = model.predict(expanded_img_array)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / np.linalg.norm(flattened_features)\n",
    "    return normalized_features\n",
    "\n",
    "def extract_features_from_dataset(directory, model, cache_path='features_cache_task2.pkl'):\n",
    "    if os.path.exists(cache_path):\n",
    "        with open(cache_path, 'rb') as f:\n",
    "            image_paths, features_list = pickle.load(f)\n",
    "    else:\n",
    "        image_paths = []\n",
    "        features_list = []\n",
    "        for subdir, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "                    img_path = os.path.join(subdir, file)\n",
    "                    features = extract_features_custom(img_path, model)\n",
    "                    image_paths.append(img_path)\n",
    "                    features_list.append(features)\n",
    "        with open(cache_path, 'wb') as f:\n",
    "            pickle.dump((image_paths, features_list), f)\n",
    "    return image_paths, features_list\n",
    "\n",
    "image_paths, features_list = extract_features_from_dataset('test', model)\n",
    "\n",
    "# Step 5: Implement the Similarity Search\n",
    "def recommend_similar_images(features, all_features, all_paths, n=10):\n",
    "    neighbors = NearestNeighbors(metric='euclidean')\n",
    "    neighbors.fit(all_features)\n",
    "    distances, indices = neighbors.kneighbors([features], n_neighbors=n)\n",
    "    return [all_paths[idx] for idx in indices.flatten()]\n",
    "\n",
    "def display_images(image_paths):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = plt.imread(img_path)\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(os.path.basename(img_path))\n",
    "    plt.show()\n",
    "\n",
    "input_image_path = 'test-pic.jpg'\n",
    "input_features = extract_features_custom(input_image_path, model)\n",
    "recommended_images = recommend_similar_images(input_features, features_list, image_paths)\n",
    "\n",
    "print(\"Recommended images:\")\n",
    "display_images(recommended_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52654d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
