{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper function to check if a file is an image\n",
    "def is_image_file(filename):\n",
    "    valid_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".gif\"]\n",
    "    return any(filename.lower().endswith(ext) for ext in valid_extensions)\n",
    "\n",
    "# Analyze dataset to count images and categorize them\n",
    "def analyze_dataset(directory):\n",
    "    count = 0\n",
    "    categories = {}\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if is_image_file(file):\n",
    "                category = subdir.split(os.sep)[-2]\n",
    "                style = subdir.split(os.sep)[-1]\n",
    "                label = f\"{category}_{style}\"\n",
    "                if label not in categories:\n",
    "                    categories[label] = 0\n",
    "                categories[label] += 1\n",
    "                count += 1\n",
    "    return count, categories\n",
    "\n",
    "# Analyze the \"Train\" directory\n",
    "image_count, category_details = analyze_dataset('Train')\n",
    "print(f\"Total images: {image_count}\")\n",
    "for category, num_images in category_details.items():\n",
    "    print(f\"{category}: {num_images} images\")\n",
    "\n",
    "# Feature extraction using EfficientNetB0\n",
    "def extract_features(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(preprocessed_img)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / np.linalg.norm(flattened_features)\n",
    "    return normalized_features\n",
    "\n",
    "# Compute average features for each category\n",
    "def compute_average_features(directory, model):\n",
    "    category_features = {}\n",
    "    category_counts = {}\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if is_image_file(file):\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                features = extract_features(img_path, model)\n",
    "                category = subdir.split(os.sep)[-2] + \"_\" + subdir.split(os.sep)[-1]\n",
    "                if category not in category_features:\n",
    "                    category_features[category] = np.zeros_like(features)\n",
    "                    category_counts[category] = 0\n",
    "                category_features[category] += features\n",
    "                category_counts[category] += 1\n",
    "    for category in category_features:\n",
    "        category_features[category] /= category_counts[category]\n",
    "    return category_features\n",
    "\n",
    "# Find the closest category for a given image\n",
    "def find_closest_category(image_path, category_features, model):\n",
    "    image_features = extract_features(image_path, model)\n",
    "    nearest_category = None\n",
    "    min_distance = float('inf')\n",
    "    for category, features in category_features.items():\n",
    "        distance = np.linalg.norm(image_features - features)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_category = category\n",
    "    return nearest_category\n",
    "\n",
    "# Extract features from all images in a specified category\n",
    "def extract_features_from_category(directory, category, model):\n",
    "    image_paths = []\n",
    "    features_list = []\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        parts = subdir.split(os.sep)\n",
    "        if len(parts) >= 2:\n",
    "            constructed_category = '_'.join(parts[-2:])  # Safely join the last two parts\n",
    "            if constructed_category == category:\n",
    "                for file in files:\n",
    "                    if is_image_file(file):\n",
    "                        img_path = os.path.join(subdir, file)\n",
    "                        image_paths.append(img_path)\n",
    "                        features = extract_features(img_path, model)\n",
    "                        features_list.append(features)\n",
    "    return image_paths, features_list\n",
    "\n",
    "# Recommend n similar images based on feature similarity\n",
    "def recommend_similar_images(features, all_features, all_paths, n=10):\n",
    "    neighbors = NearestNeighbors(n_neighbors=n, metric='euclidean')\n",
    "    neighbors.fit(all_features)\n",
    "    distances, indices = neighbors.kneighbors([features])\n",
    "    return [all_paths[idx] for idx in indices.flatten()]\n",
    "\n",
    "# Display images in a grid\n",
    "def display_images(image_paths):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = mpimg.imread(img_path)\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(os.path.basename(img_path))\n",
    "    plt.show()\n",
    "\n",
    "# Build and fine-tune EfficientNetB0 model\n",
    "def build_model():\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = GlobalMaxPooling2D()(base_model.output)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "    # Freeze the layers except the last few layers\n",
    "    for layer in base_model.layers[:-20]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "# Callbacks for early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model on your training data here\n",
    "# Assuming train_data and val_data are prepared\n",
    "# Example:\n",
    "# train_data, val_data = ...  # Prepare your data here\n",
    "\n",
    "# Uncomment the following lines if you have train_data and val_data prepared\n",
    "# model.fit(train_data, epochs=50, validation_data=val_data, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Check if the best model weights exist and load them\n",
    "if os.path.exists('best_model.keras'):\n",
    "    model.load_weights('best_model.keras')\n",
    "else:\n",
    "    print(\"Best model weights not found. Ensure you have trained the model and saved the weights.\")\n",
    "\n",
    "# Compute average features and find the closest category for images\n",
    "category_features = compute_average_features('Train', model)\n",
    "category = find_closest_category('test-pic.jpg', category_features, model)\n",
    "features = extract_features('test-pic.jpg', model)\n",
    "\n",
    "# Extract features from all images in the closest category\n",
    "image_paths, features_list = extract_features_from_category('Train', category, model)\n",
    "\n",
    "# Recommend 10 similar images\n",
    "recommended_images = recommend_similar_images(features, features_list, image_paths)\n",
    "print(f\"10 recommended images similar to your image in category {category}:\")\n",
    "for img in recommended_images:\n",
    "    print(img)\n",
    "\n",
    "# Display the recommended images\n",
    "display_images(recommended_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
